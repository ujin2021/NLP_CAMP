{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-02-tokenizer-강의.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "b7GZHAJc8R1W"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujin2021/NLP_CAMP/blob/main/day2/02_02_tokenizer_%EA%B0%95%EC%9D%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dfJPT-2XMTB"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a193aGJWVaqb",
        "outputId": "001276a6-a940-4fd5-bef8-ff5dbc9f8a05"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 19.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 10.1MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 9.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHkHg6XAXoyK"
      },
      "source": [
        "# Evn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYXFwcBXJDG"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import json\n",
        "import zipfile\n",
        "import math\n",
        "import copy\n",
        "import collections\n",
        "import re  # 정규식\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvjyruUlXtlR"
      },
      "source": [
        "## random seed initialize\n",
        "random_seed = 1234\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC3fXkhdYcYt",
        "outputId": "1a269816-8e46-4cbd-b797-e6bed7454b19"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jan 26 06:25:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVRdxYReYeQj",
        "outputId": "817a99a1-4b80-4660-cfb3-98a352250d9b"
      },
      "source": [
        "# google drive mount (data를 쓰기위해)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byCIiLJBbFHh",
        "outputId": "1ebc25f3-486e-49d3-ffca-4f22d87f5f13"
      },
      "source": [
        "# data dir(copy path)\n",
        "data_dir = '/content/drive/MyDrive/NLP/data'\n",
        "os.listdir(data_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kowiki', 'ko_32000.model', '.ipynb_checkpoints', 'ko_32000.vocab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H0BLydCb7lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca91c28-7632-42b7-87e6-03e364a88c8b"
      },
      "source": [
        "# kowiki dir\n",
        "kowiki_dir = os.path.join(data_dir, 'kowiki')\n",
        "if not os.path.exists(kowiki_dir):\n",
        "    os.makedirs(kowiki_dir)\n",
        "os.listdir(kowiki_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kowiki.txt.zip', '.ipynb_checkpoints', 'my_corpus.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEbpKyPxz6qs"
      },
      "source": [
        "# Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3xx7dJYz9jt"
      },
      "source": [
        "text = \"\"\"위키백과의 최상위 도메인이 .com이던 시절 ko.wikipedia.com에 구판 미디어위키가 깔렸으나 한글 처리에 문제가 있어 글을 올릴 수도 없는 이름뿐인 곳이었다. 2002년 10월에 새로운 위키 소프트웨어를 쓰면서 한글 처리 문제가 풀리기 시작했지만, 가장 많은 사람이 쓰는 인터넷 익스플로러에서는 인코딩 문제가 여전했다. 이런 이유로 초기에는 도움말을 옮기거나 쓰는 일에 어려움을 겪었다. 이런 어려움이 있었는데도 위키백과 통계로는, 2002년 10월에서 2003년 7월까지 열 달 사이에 글이 13개에서 159개로 늘었고 2003년 7월과 8월 사이에는 한 달 만에 159개에서 348개로 늘어났다. 2003년 9월부터는 인터넷 익스플로러의 인코딩 문제가 사라졌으며, 대한민국 언론에서도 몇 차례 위키백과를 소개하면서 참여자가 점증하리라고 예측했다. 참고로 한국어 위키백과의 최초 문서는 2002년 10월 12일에 등재된 지미 카터 문서이다.\n",
        "2005년 6월 5일 양자장론 문서 등재를 기점으로 총 등재 문서 수가 1만 개를 돌파하였고 이어 동해 11월에 제1회 정보트러스트 어워드 인터넷 문화 일반 분야에 선정되었다. 2007년 8월 9일에는 한겨레21에서 한국어 위키백과와 위키백과 오프라인 첫 모임을 취재한 기사를 표지 이야기로 다루었다.\n",
        "2008년 광우병 촛불 시위 때 생긴 신조어인 명박산성이 한국어 위키백과에 등재되고 이 문서의 존치 여부를 두고 갑론을박의 과정이 화제가 되고 각종 매체에도 보도가 되었다. 시위대의 난입과 충돌을 방지하기 위해 거리에 설치되었던 컨테이너 박스를 이명박 정부의 불통으로 풍자를 하기 위해 사용된 이 신조어는 중립성을 지켰는지와 백과사전에 올라올 만한 문서인지가 쟁점이 되었는데 일시적으로 사용된 신조어일 뿐이라는 주장과 이미 여러 매체에서 사용되어 지속성이 보장되었다는 주장 등 논쟁이 벌어졌고 다음 아고라 등지에서 이 항목을 존치하는 방안을 지지하는 의견을 남기기 위해 여러 사람이 새로 가입하는 등 혼란이 빚어졌다. 11월 4일에는 다음커뮤니케이션에서 글로벌 세계 대백과사전을 기증받았으며, 2009년 3월에는 서울특별시로부터 콘텐츠를 기증받았다. 2009년 6월 4일에는 액세스권 등재를 기점으로 10만 개 문서 수를 돌파했다.\n",
        "2011년 4월 16일에는 대한민국에서의 위키미디어 프로젝트를 지원하는 모임을 결성할 것을 추진하는 논의가 이뤄졌고 이후 창립준비위원회 결성을 거쳐 2014년 10월 19일 창립총회를 개최하였으며, 최종적으로 2015년 11월 4일 사단법인 한국 위키미디어 협회가 결성되어 활동 중에 있다. 2019년 미국 위키미디어재단으로부터 한국 지역 지부(챕터)로 승인을 받았다.\n",
        "2012년 5월 19일에는 보비 탬블링 등재를 기점으로 총 20만 개 문서가 등재되었고 2015년 1월 5일, Rojo -Tierra- 문서 등재를 기점으로 총 30만 개 문서가 등재되었다. 2017년 10월 21일에는 충청남도 동물위생시험소 문서 등재로 40만 개의 문서까지 등재되었다.\"\"\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzrQ4voTxU3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52652fd6-23ed-4e22-b592-d282f63f12b8"
      },
      "source": [
        "# wiki 내용 확인\n",
        "with zipfile.ZipFile(os.path.join(kowiki_dir, 'kowiki.txt.zip')) as z: # file을 열고 닫고 할 필요없이 with를 쓰면 with 안에서만 파일이 열리기 때문에 따로 닫아주지 않아도 된다\n",
        "    with z.open('kowiki.txt') as f:\n",
        "        for i, line in enumerate(f): # enumerate : 숫자를 부여해서\n",
        "            if i >= 100:\n",
        "                break\n",
        "            line = line.decode('utf-8').strip() # 앞뒤로 공백문자 지우기\n",
        "            print(line)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "지미 카터\n",
            "제임스 얼 \"지미\" 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39대 대통령 (1977년 ~ 1981년)이다.\n",
            "지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다. 조지아 공과대학교를 졸업하였다. 그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다. 1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다. 그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다.\n",
            "1962년 조지아 주 상원 의원 선거에서 낙선하나 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주 지사 선거에 낙선하지만 1970년 조지아 주 지사를 역임했다. 대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다. 조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다.\n",
            "1976년 미합중국 (미국) 제39대 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워서, 많은 지지를 받고 제럴드 포드 (당시 미국 대통령) 를 누르고 당선되었다.\n",
            "카터 대통령은 에너지 개발을 촉구했으나 공화당의 반대로 무산되었다.\n",
            "카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다.\n",
            "그러나 이것은 공화당과 미국의 유대인 단체의 반발을 일으켰다. 1979년 백악관에서 양국 간의 평화조약으로 이끌어졌다. 또한 소련과 제2차 전략 무기 제한 협상에 조인했다.\n",
            "카터는 1970년대 후반 당시 대한민국 등 인권 후진국의 국민들의 인권을 지키기 위해 노력했으며, 취임 이후 계속해서 도덕정치를 내세웠다.\n",
            "그러나 주 이란 미국 대사관 인질 사건에서 인질 구출 실패를 이유로 1980년 대통령 선거에서 공화당의 로널드 레이건 후보에게 져 결국 재선에 실패했다. 또한 임기 말기에 터진 소련의 아프가니스탄 침공 사건으로 인해 1980년 하계 올림픽에 반공국가들의 보이콧을 내세웠다.\n",
            "지미 카터는 대한민국과의 관계에서도 중요한 영향을 미쳤던 대통령 중 하나다. 인권 문제와 주한미군 철수 문제로 한때 한미 관계가 불편하기도 했다. 1978년 대한민국에 대한 북한의 위협에 대비해 한미연합사를 창설하면서, 1982년까지 3단계에 걸쳐 주한미군을 철수하기로 했다. 그러나 주한미군사령부와 정보기관·의회의 반대에 부딪혀 주한미군은 완전철수 대신 6,000명을 감축하는 데 그쳤다. 또한 박정희 정권의 인권 문제 등과의 논란으로 불협화음을 냈으나, 1979년 6월 하순, 대한민국을 방문하여 관계가 다소 회복되었다.\n",
            "1979년 ~ 1980년 대한민국의 정치적 격변기 당시의 대통령이었던 그는 이에 대해 애매한 태도를 보였고, 이는 후에 대한민국 내에서 고조되는 반미 운동의 한 원인이 됐다. 10월 26일, 박정희 대통령이 김재규 중앙정보부장에 의해 살해된 것에 대해 그는 이 사건으로 큰 충격을 받았으며, 사이러스 밴스 국무장관을 조문사절로 파견했다. 12·12 군사 반란과 5.17 쿠데타에 대해 초기에는 강하게 비난했으나, 미국 정부가 신군부를 설득하는데, 한계가 있었고 결국 묵인하는 듯한 태도를 보이게 됐다.\n",
            "퇴임 이후 민간 자원을 적극 활용한 비영리 기구인 카터 재단을 설립한 뒤 민주주의 실현을 위해 제 3세계의 선거 감시 활동 및 기니 벌레에 의한 드라쿤쿠르스 질병 방재를 위해 힘썼다. 미국의 빈곤층 지원 활동, 사랑의 집짓기 운동, 국제 분쟁 중재 등의 활동도 했다.\n",
            "카터는 카터 행정부 이후 미국이 북핵 위기, 코소보 전쟁, 이라크 전쟁과 같이 미국이 군사적 행동을 최후로 선택하는 전통적 사고를 버리고 군사적 행동을 선행하는 행위에 대해 깊은 유감을 표시 하며 미국의 군사적 활동에 강한 반대 입장을 보이고 있다.\n",
            "특히 국제 분쟁 조정을 위해 북한의 김일성, 아이티의 세드라스 장군, 팔레인스타인의 하마스, 보스니아의 세르비아계 정권 같이 미국 정부에 대해 협상을 거부하면서 사태의 위기를 초래한 인물 및 단체를 직접 만나 분쟁의 원인을 근본적으로 해결하기 위해 힘썼다. 이 과정에서 미국 행정부와 갈등을 보이기도 했지만, 전직 대통령의 권한과 재야 유명 인사들의 활약으로 해결해 나갔다.\n",
            "1978년에 채결된 캠프데이비드 협정의 이행이 지지부진 하자 중동 분쟁 분제를 해결하기 위해 1993년 퇴임 후 직접 이스라엘과 팔레인스타인의 오슬로 협정을 이끌어 내는 데도 성공했다.\n",
            "1993년 1차 북핵 위기 당시 북한에 대한 미국의 군사적 행동이 임박했으나, 미국 전직 대통령으로는 처음으로 북한을 방문하고 미국과 북 양국의 중재에 큰 기여를 해 위기를 해결했다는 평가를 받았다. 또한 이 때 김영삼 대통령과 김일성 주석의 만남을 주선했다. 하지만 그로부터 수주일 후 김일성이 갑자기 사망하여 김일성과 김영삼의 정상회담은 이루어지지 못했다.\n",
            "미국의 관타나모 수용소 문제, 세계의 인권문제에서도 관심이 깊어 유엔에 유엔인권고등판무관의 제도를 시행하도록 노력하여 독재자들의 인권 유린에 대해 제약을 하고, 국제형사재판소를 만드는 데 기여하여 독재자들 같은 인권유린범죄자를 재판소로 회부하여 국제적인 처벌을 받게 하는 등 인권 신장에 크나 큰 기여를 했다.\n",
            "2011년 4월 26일부터 29일까지 북한을 3일간 방문했다.\n",
            "경제문제를 해결하지 못하고 주 이란 미국 대사관 인질 사건에 발목이 잡혀 실패한 대통령으로 평가를 받지만 이란 사태는 미국 내 이란 재산을 풀어주겠다는 조건을 내세워서 사실상 카터가 해결한 것이었고, 사랑의 집짓기 운동 등으로 퇴임 후에 훨씬 더 존경받는 미국 대통령 중에 특이한 인물로 남았다.\n",
            "그는 2002년 말 인권과 중재 역할에 대한 공로를 인정받아 노벨 평화상을 받게 되었다.\n",
            "\n",
            "\n",
            "\n",
            "수학\n",
            "수학(數學, )은 양, 구조, 공간, 변화등을 다룬다고 설명 할 수 있으나 일반적으로 받아들여지는 정의는 없다 수학은 공리, 명제, 증명 등으로 구성된 추상적 대상을 연구하는 학문이다. 수학자는 인간이 살아가는 실제 세상과 대비해 보았을 때 전혀 다른 독립적이며 추상적이고 엄격한 구조를 만들고 연구한다.\n",
            "그러나 이런 추상적인 사실들이 가끔은 실제를 설명하는데 필요한 경우도 있다. 고대로부터 문명이 생기는데 필요한 건축, 천문학, 토지 측량, 기계 공학, 상업 등에 수학적 개념들이 응용되어왔다.\n",
            "수학에서는 예술에서 그렇듯 실용적 고려를 하지 않으며, 거의 모두 실용성을 가지지 않지만, 극히 일부 실용적인 부분도 있다. 응용 수학에서는 이렇게 수학을 물리학, 화학, 생물학, 공학, 경제학, 사회학 등 다른 학문에 응용하는데 관심이 있다.\n",
            "또한 수학은 음악이나 미술 등 예술과도 관련이 있다. 피타고라스는 두 정수의 비율이 듣기 좋은 소리가 난다는 점을 가지고 피타고라스 음계를 만들었다. 중세시대에도 음악과 수학을 밀접하게 연관시켰으며 성 빅토르의 후고는 “음악은 조화다”라고 했고, 성 트론드의 루돌프는 “음악은 조화의 토대(ratio)다”라고 쓴 바 있다. 조화가 반드시 소리로 표현될 필요는 없고 소리의 음악은 음악의 형식 중 하나에 불과했다. 소리에 대해 다루었던 중세의 저술가들이 있는가 하면, 조화와 비례의 추상적 이론만을 다루고 소리에는 거의 관심을 보이지 않았던 저술가들도 있었다. 청각적인 면과 추상적인 면이라는 음악의 이런 이중적 측면은 고대의 음악이론보다는 중세의 음악이론에서 큰 특징이 되었다. 또한 현대 음악을 군(群,group)같은 수학적 대상을 이용해 분석하기도 한다. 원근법은 사영 기하학에 해당한다. 미술 사조 중 하나인 입체파도 기하학의 영향을 받았다.\n",
            "오늘날 수학은 자연과학, 공학뿐만 아니라, 경제학 등의 사회과학에서도 중요한 도구로 사용된다. 예를들어, 정도의 차이는 있으나, 미적분학과 선형대수학은 자연과학과 공학, 경제학을 하는데에 필수적 과목으로 여겨지며, 확률론은 계량경제학에 응용된다. 통계학은 사회과학이론에 근거를 마련하는데 필수적이다. 16세기에 갈릴레오 갈릴레이가 \"자연이라는 책은 수학이라는 언어로 기록되어 있다.\"는 주장과 함께 물리학에 수학적 방법을 도입하였고, 17세기에 아이작 뉴턴이 고전 역학의 기본 물리학 법칙들을 수학적으로 기술하고 정립하여 물리학 이론에서 수학적 모델링은 필수적 요소가 되었다. 또한 이 시기는 과학적 방법이 정립되는 시기이기도 한데, 많은 과학적 현상들이 수학적 관계가 있음이 드러나면서 과학적 방법에도 수학은 중요한 역할을 하고 있다. 노벨 물리학상 수상자 유진 위그너는 그의 에세이 \"The unreasonable effectiveness of mathematics in natural sciences\"에서 인간 세상과 동떨어져있고 현실과 아무 관련이 없다고 여겨지던 수학 중 극히 일부는 뜻밖에도 자연과학과 연관성이 드러나고 과학이론에 효과적인 토대를 마련해 주는데에 대한 놀라움을 표현하였다. 예를 들어, 비유클리드기하와 3차원 이상의 임의의 차원에서 기하학을 탐구했던 미분 기하학은 당시에는 현실과 연관성을 가지지 않았으나 먼 훗날 일반상대성이론이 4차원 기하학을 필요로 함에 따라, 물리적 세상과 연관이 있음이 밝혀졌다. 또한 게이지이론, 양자장론 등에도 미분 기하학은 필수적이다.\n",
            "mathematics라는 단어는 '아는 모든 것'라는 뜻의 고대 그리스어 mathematikos에서 유래되었다. 줄여서 math라고 표현을하기도 한다.\n",
            "수학은 기원전 600년 경에 살았던 탈레스로부터 시작됐다. 하지만 탈레스가 태어나기 전에도 수학을 연구한 사람이 있을 수도 있기 때문에 인류의 역사와 더불어 시작되었다고 할 수 있다. 교역•분배•과세 등의 인류의 사회 생활에 필요한 모든 계산을 수학이 담당해 왔고, 농경 생활에 필수적인 천문 관측과 달력의 제정, 토지의 측량 또한 수학이 직접적으로 관여한 분야이다. 고대 수학을 크게 발전시킨 나라로는 이집트, 인도, 그리스, 중국 등이 있다. 그 중에서도 그리스는 처음으로 방정식에서 변수를 문자로 쓴 나라이다.\n",
            "한국의 수학은 약 1,500년 전부터 기록으로 보이기 시작한다. 신라 시대에 수학을 가르쳤으며, 탈레스가 최초로 발견한 일식과 월식을 예측할 정도로 발달했다. 조선 시대에 훈민정음을 창제한 세종 대왕은 집현전 학자들에게 수학 연구를 명하는 등, 조선의 수학 수준을 향상시키기 위해서 많은 노력을 기울였다. 하지만 임진왜란으로 많은 서적들이 불타고, 천문학 분야에서 큰 손실을 입었다. 조선 후기의 한국의 수학은 실학자들을 중심으로 다시 발전하였고, 새로운 결과도 성취되었다.\n",
            "수학의 각 분야들은 상업에 필요한 계산을 하기 위해, 숫자들의 관계를 이해하기 위해, 토지를 측량하기 위해, 그리고 천문학적 사건들을 예견하기 위해 발전되어왔다. 이 네 가지 목적은 대략적으로 수학이 다루는 대상인 양, 구조, 공간 및 변화에 대응되며, 이들을 다루는 수학의 분야를 각각 산술, 대수학, 기하학, 해석학이라 한다. 또한 이 밖에도 근대 이후에 나타난 수학기초론과 이산수학 및 응용수학 등이 있다.\n",
            "산술은 자연수와 정수 및 이에 대한 사칙연산에 대한 연구로서 시작했다. 수론은 이런 주제들을 보다 깊게 다루는 학문으로, 그 결과로는 페르마의 마지막 정리 등이 유명하다. 또한 쌍둥이 소수 추측과 골드바흐 추측 등을 비롯해 오랜 세월 동안 해결되지 않고 남아있는 문제들도 여럿 있다.\n",
            "수의 체계가 보다 발전하면서, 정수의 집합을 유리수의 집합의 부분집합으로 여기게 되었다. 또한 유리수의 집합은 실수의 집합의 부분집합이며, 이는 또다시 복소수 집합의 일부분으로 볼 수 있다. 여기에서 더 나아가면 사원수와 팔원수 등의 개념을 생각할 수도 있다. 이와는 약간 다른 방향으로, 자연수를 무한대까지 세어나간다는 개념을 형식화하여 순서수의 개념을 얻으며, 집합의 크기 비교를 이용하여 무한대를 다루기 위한 또다른 방법으로는 기수의 개념도 있다.\n",
            "수 대신 문자를 써서 문제해결을 쉽게 하는 것과, 마찬가지로 수학적 법칙을 일반적이고 간명하게 나타내는 것을 포함한다. 고전대수학은 대수방정식 및 연립방정식의 해법에서 시작하여 군, 환, 체 등의 추상대수학을 거쳐 현대에 와서는 대수계의 구조를 보는 것을 중심으로 하는 선형대수학으로 전개되었다. 수의 집합이나 함수와 같은 많은 수학적 대상들은 내재적인 구조를 보인다. 이러한 대상들의 구조적 특성들이 군론, 환론, 체론 그리고 그 외의 수많은 대수적 구조들을 연구하면서 다루어지며, 그것들 하나하나가 내재적 구조를 지닌 수학적 대상이다. 이 분야에서 중요한 개념은 벡터, 벡터 공간으로의 일반화, 그리고 선형대수학에서의 지식들이다. 벡터의 연구에는 산술, 대수, 기하라는 수학의 중요한 세개의 분야가 조합되어 있다. 벡터 미적분학은 여기에 해석학의 영역이 추가된다. 텐서 미적분학은 대칭성과 회전축의 영향 아래에서 벡터의 움직임을 연구한다. 눈금없는 자와 컴퍼스와 관련된 많은 고대의 미해결 문제들이 갈루아 이론을 사용하여 비로소 해결되었다.\n",
            "공간에 대한 연구는 기하학에서 시작되었고, 특히 유클리드 기하학에서 비롯되었다. 삼각법은 공간과 수들을 결합하였고, 잘 알려진 피타고라스의 정리를 포함한다. 현대에 와서 공간에 대한 연구는, 이러한 개념들은 더 높은 차원의 기하학을 다루기 위해 비유클리드 기하학(상대성이론에서 핵심적인 역할을 함)과 위상수학으로 일반화되었다. 수론과 공간에 대한 이해는 모두 해석 기하학, 미분기하학, 대수기하학에 중요한 역할을 한다. 리 군도 공간과 구조, 변화를 다루는데 사용된다. 위상수학은 20세기 수학의 다양한 지류속에서 괄목할만한 성장을 한 분야이며, 푸앵카레 추측과 인간에 의해서 증명되지 못하고 오직 컴퓨터로만 증명된 4색정리를 포함한다.\n",
            "변화에 대한 이해와 묘사는 자연과학에 있어서 일반적인 주제이며, 미적분학은 변화를 탐구하는 강력한 도구로서 발전되었다. 함수는 변화하는 양을 묘사함에 있어서 중추적인 개념으로써 떠오르게 된다. 실수와 실변수로 구성된 함수의 엄밀한 탐구가 실해석학이라는 분야로 알려지게 되었고, 복소수에 대한 이와 같은 탐구 분야는 복소해석학이라고 한다. 함수해석학은 함수의 공간(특히 무한차원)의 탐구에 주목한다. 함수해석학의 많은 응용분야 중 하나가 양자역학이다. 많은 문제들이 자연스럽게 양과 그 양의 변화율의 관계로 귀착되고, 이러한 문제들이 미분방정식으로 다루어진다. 자연의 많은 현상들이 동역학계로 기술될 수 있다. 혼돈 이론은 이러한 예측 불가능한 현상을 탐구하는 데 상당한 기여를 한다.\n",
            "수학의 기초를 확실히 세우기 위해, 수리논리학과 집합론이 발전하였고, 이와 더불어 범주론이 최근에도 발전되고 있다. “근본 위기”라는 말은 대략 1900년에서 1930년 사이에 일어난, 수학의 엄밀한 기초에 대한 탐구를 상징적으로 보여주는 말이다. 수학의 엄밀한 기초에 대한 몇 가지 의견 불일치는 오늘날에도 계속되고 있다. 수학의 기초에 대한 위기는 그 당시 수많은 논쟁에 의해 촉발되었으며, 그 논쟁에는 칸토어의 집합론과 브라우어-힐베르트 논쟁이 포함되었다.\n",
            "\n",
            "\n",
            "\n",
            "수학 상수\n",
            "수학에서 상수란 그 값이 변하지 않는 불변량으로, 변수의 반대말이다. 물리 상수와는 달리, 수학 상수는 물리적 측정과는 상관없이 정의된다.\n",
            "수학 상수는 대개 실수체나 복소수체의 원소이다. 우리가 이야기할 수 있는 상수는 (거의 대부분 계산 가능한) 정의가능한 수이다.\n",
            "특정 수학 상수, 예를 들면 골롬-딕맨 상수, 프랑세즈-로빈슨 상수, formula_1, 레비 상수와 같은 상수는 다른 수학상수 또는 함수와 약한 상관관계 또는 강한 상관관계를 갖는다.\n",
            "\n",
            "\n",
            "\n",
            "문학\n",
            "문학(文學, )은 언어를 예술적 표현의 제재로 삼아 새로운 의미를 창출하여, 인간과 사회를 진실되게 묘사하는 예술의 하위분야이다. 간단하게 설명하면, 언어를 통해 인간의 삶을 미적(美的)으로 형상화한 것이라고 볼 수 있다. 문학은 원래 문예(文藝)라고 부르는 것이 옳으며, 문학을 학문의 대상으로서 탐구하는 학문의 명칭 역시 문예학이다. 문예학은 음악사학, 미술사학 등과 함께 예술학의 핵심분야로서 인문학의 하위범주에 포함된다.\n",
            "일반적으로 문학의 정의는 텍스트들의 집합이다. 각각의 국가들은 고유한 문학을 가질 수 있으며, 이는 기업이나 철학 조류, 어떤 특정한 역사적 시대도 마찬가지이다. 흔히 한 국가의 문학을 묶어서 분류한다. 예를 들어 고대 그리스어, 성서, 베오울프, 일리아드, 그리고 미국 헌법 등이 그러한 분류의 범주에 들어간다. 좀 더 일반적으로는 문학은 특정한 주제를 가진 이야기, 시, 희곡의 모음이라 할 수 있다. 이 경우, 이야기, 시, 그리고 희곡은 민족주의적인 색채를 띨 수도 아닐 수도 있다. 문학의 한 부분으로서 특정한 아이템을 구분 짓는 일은 매우 어려운 일이다. 어떤 사람들에게 \"문학\"은 어떠한 상징적인 기록의 형태로도 나타날 수 있는 것이다. (이를테면 이미지나 조각, 또는 문자로도 나타날 수 있다.) 그러나 또다른 사람들에게 있어 문학은 오직 문자로 이루어진 텍스트로 구성된 것만을 포함한다. 좀 더 보수적인 사람들은 그 개념이 꼭 물리적인 형태를 가진 텍스트여야 하고, 대개 그러한 형태는 종이 등의 눈에 보이는 매체에서 디지털 미디어까지 다양할 수 있다.\n",
            "더 나아가 보면, \"문학\"과 몇몇 인기있는 기록형태의 작업들, 소위 \"대중문학\" 사이에는 인식가능한 차이점이 존재한다. 이때 \"문학적인 허구성\"과 \"문학적인 재능\"이 종종 개별적인 작품들을 구별하는 데에 사용된다. 예를 들어, 찰스 디킨즈의 작품들은 대부분의 사람들에게 \"문학적인 것\"으로 받아들여지지만, 제프리 아처의 작품들은 영문학이라는 일반적인 범주 아래 두기에는 다소 가치가 떨어지는 것으로 생각된다. 또한 예를 들어 문법과 어법에 서투르거나, 이야기가 혼란스러워 신뢰성을 주지 않거나, 인물들의 성격에 일관성이 없을 경우에도 문학에서 제외될 수 있다. 로맨스, 범죄소설, 과학소설 등의 장르 소설도 때로 \"문학\"이 아닌 것으로 간주되는 경우도 있다. 이들은 대부분 \"대중문학\"의 범주에 포함된다.\n",
            "문학은 분류하는 방법에 따라 다음과 같이 구분한다.\n",
            "이 외에도 편의에 따라 발생적으로 대별하기도 한다.\n",
            "문학은 처음은 유일한 종류, 즉 노래하고, 말하고, 춤춘다는 것이 분화되지 않은 것이었다. 이 춤추는 것을 중심으로 발달한 것이 연극(演劇)이며, 노래하는 것이 발달하여 시(詩), 말하는 것이 발달하여 산문(散文)의 이야기가 되었다. 시는 정형시·자유시·산문시로, 또한 서사시와 서정시로 나뉜다. 산문은 사건을 중심으로 그려진 이야기, 근대 리얼리즘의 수법 이후 인물의 성격을 묘사하는 것을 중심으로 한 소설이 있다. 이야기나 소설과 같이 특별한 구상에 의하지 않고, 작자의 흥미에 의해서 씌어지는 것이 잡문(雜文) 또는 수필이며, 이것이 날짜에 따라 씌어지는 것이 일기, 여행의 과정에 따라 씌어지는 것이 기행문이다. 일기와 마찬가지로 발표의 의도가 작은 것에 서간(書簡)이 있다. 이 밖에 사건의 경험에 따른 회고록, 사건 등의 특정시(特定時)에 한정되지 않는 자서전, 제삼자에 의해서 씌어지는 전기(傳記)가 있다. 또한 이것들을 포함하는 예술작품의 가치평가를 시도하는 것이 평론(評論)이다.\n",
            "대중문학이란 상업성을 띠며 대중을 겨냥하여 그들의 통속적인 흥미와 욕구를 채워주는 문학을 말한다. 대중문학의 하위장르에는 여러가지가 있다.\n",
            "문학을 창작하는 예술가를 문예가라고 부른다. 문예학을 연구하는 사람을 문예학자라고 부른다. 문학을 창작하는 사람을 따로 저술가라고 한다. 문예학자와 언어학자를 합쳐 어문학자로 칭하기도 한다. 그러나 언어와, 언어를 사용한 예술인 문학은 현격한 차이가 있으므로 주의해야 한다.\n",
            "반영론적 관점에 의한 감상은 작품을 창작된 당시 시대 정황과 연결시켜 감상하는 입장이고, 내재적 관점의 감상은 작품의 형식, 내용에 국한하여 감상하는 것이다. 표현론적 관점의 감상은 작가의 전기적 사실과 작품을 연결시켜 감상하는 것이고, 수용론적 관점의 감상은 독자와 작품을 연결시켜 감상하는 것을 말한다.\n",
            "\n",
            "\n",
            "\n",
            "나라 목록\n",
            "이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\n",
            "이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\n",
            "두 목록은 모두 가나다 순이다.\n",
            "일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.\n",
            "이 목록은 주권을 주장하고 점유한 영토를 실제로 관리하고 있으나, 많은 국가와 외교관계를 맺지 못한 나라를 설명하고 있다. 극소형 국가는 이 목록에 포함하지 않는다.\n",
            "이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 하였다. 협정에 따르면, 국가는 다음의 조건을 만족해야 한다.\n",
            "특히, 마지막 조건은 국제 공동체의 참여 용인을 내포하고 있기 때문에, 다른 나라의 승인이 매우 중요한 역할을 할 수 있다. 이 목록에 포함된 모든 국가는 보통 이 기준을 만족하는 것으로 보이는 자주적이고 독립적인 국가이다. 하지만 몬테비데오 협약 기준을 만족하는지의 여부는 많은 국가가 논쟁이 되고 있는 실정이다. 또한, 몬테비데오 협약 기준만이 국가 지위의 충분한 자격이든 아니든, 국제법의 견해 차이는 존재할 수 있다. 이 물음에 대한 다른 이론에 대한 고리는 아래에서 볼 수 있다.\n",
            "위 기준에 논거하여 이 목록은 다음 206개 국가를 포함하고 있다.\n",
            "위 목록에 포함되지 않은 다음 국가는 몬테비데오 협약의 모든 조건을 만족하지 못하거나, 자주적이고 독립적임을 주장하지 않는 국가이다.\n",
            "\n",
            "\n",
            "\n",
            "화학\n",
            "화학(化學, )은 물질의 성질, 조성, 구조, 변화 및 그에 수반하는 에너지의 변화를 연구하는 자연과학의 한 분야이다. 물리학도 역시 물질을 다루는 학문이지만, 물리학이 원소와 화합물을 모두 포함한 물체의 운동과 에너지, 열적·전기적·광학적·기계적 속성을 다루고 이러한 현상으로부터 통일된 이론을 구축하려는 것과는 달리 화학에서는 물질 자체를 연구 대상으로 한다. 화학은 이미 존재하는 물질을 이용하여 특정한 목적에 맞는 새로운 물질을 합성하는 길을 제공하며, 이는 농작물의 증산, 질병의 치료 및 예방, 에너지 효율 증대, 환경오염 감소 등 여러 가지 이점을 제공한다.\n",
            "영어 ‘케미스트리(chemistry)’는 연금술을 뜻하는 단어 ‘알케미(alchemy)’에서 비롯하였다. 이는 다시 아랍어 ‘알 키미야(, al-kīmiyāʾ)’에서 왔는데, 이 단어의 어원에 대해서는 여러 가지 설이 있다.\n",
            "‘화학(化學)’이란 단어는 물질의 변화를 다루는 학문이라는 점에 착안한 번역어이다. 이 번역어는 의 《항해술기(航海述奇)》(1866), 의 자연과학 교과서 《격물입문(格物入門)》(1866) 등에서 처음 쓰였다.\n",
            "고대 화학\n",
            "<nowiki>*</nowiki>\"초기 야금 (야금: 금속을 광석으로부터 추출하고 정련하는 기술)\"\n",
            "인간에 의해 발견된 최초의 기록된 금속은 금인 것으로 보이며 구석기 후기(BC 40,000)에 스페인 동굴에서 소량의 천연 금이 발견되었다고 한다.\n",
            "은, 구리, 주석 및 유성 철 또한 고대 문화에서 일부 제한된 양의 금속 가공을 허용하면서 고대문화로 발견 될 수 있었다. 기원전 3000년경 유성 철제로 만든 이집트 무기는 \"천국의 단검\"으로 높이 평가 받았다.\n",
            "아마도 통제 된 방식으로 사용 된 최초의 화학 반응은 불이였다. 그러나 천년 동안 불은 단순히 열과 빛을 생성하면서 한 물질을 다른 물질 (타는 나무 또는 끓는 물)로 변형시킬 수있는 신비한 힘으로만 알려졌다. 불은 초기 사회의 여러 측면에 영향을 미쳤다. 이들은 요리 및 서식지 조명과 같은 일상 생활의 가장 단순한면에서 도기, 벽돌 및 금속을 녹여 도구를 만드는 것과 같은 고급 기술에 이르기까지 다양했다.\n",
            "유리의 발견과 금속의 정화로 이어지는 불로 인해 야금이 부상했다. 야금의 초기 단계에서 금속의 정화 방법이 요구되었고, 금은 BC 2900 년 초기의 고대 이집트의 귀중한 금속이되었다.\n",
            "17 세기와 18 세기 : 초기 화학\n",
            "\"<nowiki>*</nowiki>로버트 보일\"\n",
            "영국계 미국인 화학자 로버트 보일 (Robert Boyle, 1627-1691)은 연금술에 대한 현대의 과학적 방법을 정제하고 화학을 연금술과 분리한 것으로 생각된다. 그의 연구가 연금술 전통에 뿌리를두고 있음에도 불구하고, 보일은 오늘날 현대의 화학자이자 현대화학의 창시자이자 현대 실험 과학 방법의 선구자 중 한 사람으로 불리고 있다. 보일이 원래 발견자가 아님에도 보일은 1662 년에 제시한 보일의 법칙으로 가장 잘 알려져있다. 보일의 법칙은 온도만 폐쇄된 시스템 내에서 일정하게 유지된다면 가스의 절대 압력과 부피가 반비례함을 의미한다. 보일은 또한 화학 분야의 초석으로 간주되는 1661 년의 《의심 많은 화학자》 에 대한 획기적인 저서로 인정받고 있다. 작품에서 보일은 모든 현상이 움직이는 입자의 충돌의 결과라는 가설을 제시한다. 보일 (Boyle)은 화학자들에게 실험을 호소했으며 실험은 지구, 화염, 공기 및 물과 같은 고전적인 4 가지 원소만으로 화학 원소를 제한한다는 것을 부인했다. 그는 또한 화학이 의학이나 연금술에 종속되어 과학의 지위로 부상하는 것을 중단해야 한다고 촉구했다. 중요한 것은 과학 실험에 대한 엄격한 접근 방식이라고 주장했다. 그는 모든 이론이 사실로 간주되기 전에 실험적으로 입증되어야 한다고 믿었다. 이 작품은 원자, 분자 및 화학 반응의 가장 초기의 현대적인 아이디어를 포함하고 있으며 현대 화학의 역사의 시작을 나타낸다. 보일은 또한 화학 물질을 정제하여 재현 가능한 반응을 얻으려고 시도했다. 그는 재료 물질의 물리적 특성과 상호 작용을 설명하고 정량화하기 위해 René Descartes가 제안한 기계 철학의 보컬 지지자였다. 보일은 원자핵론자 였지만 원자보다 더 많은 입자를 선호했다. 그는 속성이 유지되는 물질의 가장 정밀한 부분은 미립자의 수준에 있다고 논평했다. 그는 또한 공기 펌프로 수 많은 조사를 수행했으며, 공기가 펌프로 퍼져 나감에 따라 수은이 떨어지는 것으로 나타났다. 그는 또한 컨테이너에서 공기를 펌핑하면 화염을 없애고 내부에 있는 작은 동물을 죽일 수 있음을 관찰했다.\n",
            "과거 화학에서 더 이상 나뉘지 않는 기초적인 요소가 존재한다고 했는데, 이 기초적인 요소를 원자(atom)라 한다. 원자란 물질을 구성하는 기본적인 입자로 고대 그리스의 데모크리토스에서부터 그 존재가 주장되었는데, 1803년 존 돌턴에 의해서 원자론으로 정리되었다. 20세기 초, 화학자들은 원자를 구성하는 더 작은 입자들, 즉 전자, 양성자, 중성자가 존재한다는 사실을 발견하였다. 전자는 음전하를 띠고 있고, 양성자는 양전하를 띠고 있으며, 중성자는 전하를 띠지 않고 있다. 원자는 양성자와 중성자로 구성되어 있는 원자핵을 가지고 있으며 전자는 이 주변에 오비탈을 이루며 분포되어 있다.\n",
            "원소(element)는 일반적인 화학적, 물리학적 방법으로는 분해되지 않는 물질을 의미한다. 원소는 원자핵에 존재하는 양성자 수로 정의되는 원자 번호로 구별된다. 산소, 황, 주석, 철 등은 원소이다. 19세기 중엽까지 약 80가지의 원소가 발견되었는데, 이들은 주기율에 따라 배열될 수 있다.\n",
            "동위원소는 아이소토프 또는 동위체라고도 한다. 서로 화학적으로는 거의 구별하지 못하지만 그것을 구성하고 있는 원자의 질량이 서로 다른 원소를 동위원소라고 한다. 영어의 isotope는 그리스어인 isos(같은)와 topos(장소)의 합성어인데, 질량은 서로 달라도 원소의 주기율표에서 같은 장소에 배열되는 데서 1901년 영국의 화학자 F. 소디가 isotope라는 명칭을 붙였다. 대부분의 원소는 동위 원소를 가진다. 동위 원소는 원자 번호는 같으나, 중성자수가 다른 원소를 뜻한다. 동위 원소는 화학적인 성질은 동일하나, 원자량의 차이를 이용하여 분리할 수 있다. 자연에서도 발견되는 92개의 원소 중 88개는 동위 원소가 지표면 상에 존재한다. 자연에서 발견되지 않더라도 동위 원소는 핵반응을 이용하여 만들어낼 수 있다. 어떤 동위 원소는 방사능을 가지기도 하는데, 이 경우 동위 원소의 원자핵은 불안정하고 방사선을 방출하며 자연적으로 붕괴된다.\n",
            "동중 원소(isobar)는 원자 질량은 같으나, 양성자수가 다른 원소를 뜻한다. 동중 원소는 화학적, 물리적 성질이 다르며 S, Cl, Ar, K, Ca등이 있다.\n",
            "분자란 원자의 결합체 중 독립 입자로서 작용하는 단위체이다. 일정한 개수의 원자가 특정하게 정렬되어 서로 결합해 분자가 형성된다. 원자가 원소의 최소단위이듯, 분자는 화합물의 최소단위가 된다. 원자가 결합될 때 전자의 재배치가 일어나는데, 이는 화학에서의 중요한 관심사중 하나이다.\n",
            "화학 반응은 원자 혹은 분자가 화학적인 변화를 겪는 일을 말한다. 화학 반응은 원자간의 결합이 끊어지는 일과 다시 이어지는 일을 포함한다. 결합이 끊어질 때는 에너지가 흡수되고, 결합이 이어질 때는 에너지가 방출된다. 화학 반응의 간단한 예로는 수소와 산소가 반응하여 물이 되는 것을 들 수 있다. 반응식은 다음과 같다.\n",
            "반응식에서 알 수 있듯이, 화학 반응에서는 원자가 새로 생성되거나 나타나는 일이 일어나지 않는다. ΔH는 에너지 또는 엔탈피 변화를 뜻한다. 반응은 발열반응일 수도 있고, 흡열반응일 수도 있다. 발열반응은 주위로 열을 방출하는 반응으로 엔탈피 변화가 음수로 나타난다. 반면에 흡열반응은 주위 열을 흡수하는 반응으로 엔탈피 변화가 양수로 나타난다. 위 반응의 경우는 발열반응인데, 이는 계로부터 주위로 열이 이동하였다는 의미이다.\n",
            "화학 결합을 주된 세 가지 부류로 나누어보면 이온 결합, 공유 결합 그리고 금속결합으로 나눌 수 있다. 이온이란 전하를 띤 원자 또는 분자를 뜻한다. 이온 결합은 양전하와 음전하의 전기적인 인력에 의해서 생성되는 화학 결합이다. 예를 들면 염화 나트륨은 양전하를 띤 나트륨 이온(Na)과 음전하를 띤 염화 이온(Cl) 사이의 전기적인 결합으로 이루어진 이온 화합물이다. 이러한 물질을 물에 녹이면 이온은 물 분자에 의해 수화되고 이렇게 해서 만들어진 수용액은 전기전도도를 가진다.\n",
            "공유 결합은 원자 궤도|오비탈이 겹쳐진 결과 두 원자가 전자쌍을 공유하게 되어 생성되는 결합을 의미한다. 공유 결합이 형성되는 결합은 발열반응인데, 이때 방출되는 에너지의 양이 그 결합의 결합 에너지이다. 결합 에너지만큼의 에너지를 그 결합에 가해주면 결합은 끊어질 수 있다.\n",
            "금속 결합은 금속 원자에서 전자들이 떨어져 나와 자유전자를 생성하게 되어 생성되는 결합을 의미한다. 금속의 특성인 연성과 전성이 생성되는 이유이기도 하다.\n",
            "화합물은 구성하고 있는 원자의 종류, 수, 배치에 의해서 그 특성이 결정된다. 자연에서 찾을 수 있거나 인공적으로 합성할 수 있는 화합물의 수는 엄청나고, 이들 중 대부분은 유기 화합물이다. 유기 화합물을 이루는 주된 화학 원소인 탄소는 다른 화학 원소와는 다르게 매우 긴 사슬 형태로 정렬될 수 있으며, 같은 수많은 이성질체를 형성할 수 있다. 예를 들어, 분자식 CHO는 약 천 개의 서로 다른 화합물을 뜻할 수 있다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0oIVxJY0BP9"
      },
      "source": [
        "# Char Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQKUECFJjbBq",
        "outputId": "5107bcdb-7572-46f9-cf77-64d8dcc854ca"
      },
      "source": [
        "aa = collections.defaultdict(int)\r\n",
        "aa['bb']\r\n",
        "aa"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {'bb': 0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUMAtE0neey7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d3d886-1243-4871-ca4d-45c9ca493142"
      },
      "source": [
        "char_counter = collections.defaultdict(int) # 자동으로 0을 만들어주는 dict\n",
        "# char 개수 확인\n",
        "with zipfile.ZipFile(os.path.join(kowiki_dir, 'kowiki.txt.zip')) as z:\n",
        "    with z.open('kowiki.txt') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 100000: # 10만 line\n",
        "                break\n",
        "            line = line.decode('utf-8').strip()\n",
        "            for c in line:\n",
        "                char_counter[c] += 1\n",
        "len(char_counter)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUgW7RtzioRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b594f0d-3546-45f0-a8b4-10527fc62040"
      },
      "source": [
        "list(char_counter.items())[:100]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('지', 123099),\n",
              " ('미', 25881),\n",
              " (' ', 3034409),\n",
              " ('카', 13719),\n",
              " ('터', 19622),\n",
              " ('제', 55447),\n",
              " ('임', 12950),\n",
              " ('스', 68934),\n",
              " ('얼', 1362),\n",
              " ('\"', 21543),\n",
              " ('주', 62657),\n",
              " ('니', 19445),\n",
              " ('어', 73342),\n",
              " ('(', 69871),\n",
              " (',', 175903),\n",
              " ('1', 115707),\n",
              " ('9', 55493),\n",
              " ('2', 62377),\n",
              " ('4', 31403),\n",
              " ('년', 69536),\n",
              " ('0', 72055),\n",
              " ('월', 27540),\n",
              " ('일', 63346),\n",
              " ('~', 3517),\n",
              " (')', 69954),\n",
              " ('는', 220698),\n",
              " ('민', 27615),\n",
              " ('당', 27610),\n",
              " ('출', 11416),\n",
              " ('신', 32397),\n",
              " ('국', 68735),\n",
              " ('3', 36097),\n",
              " ('대', 100683),\n",
              " ('통', 24397),\n",
              " ('령', 9735),\n",
              " ('7', 28253),\n",
              " ('8', 33276),\n",
              " ('이', 312940),\n",
              " ('다', 279190),\n",
              " ('.', 227889),\n",
              " ('조', 35246),\n",
              " ('아', 72554),\n",
              " ('섬', 2519),\n",
              " ('운', 17477),\n",
              " ('티', 7305),\n",
              " ('플', 3806),\n",
              " ('레', 13160),\n",
              " ('인', 87587),\n",
              " ('마', 27668),\n",
              " ('을', 155879),\n",
              " ('에', 231250),\n",
              " ('서', 114998),\n",
              " ('태', 13110),\n",
              " ('났', 3043),\n",
              " ('공', 35992),\n",
              " ('과', 62245),\n",
              " ('학', 39986),\n",
              " ('교', 37519),\n",
              " ('를', 93642),\n",
              " ('졸', 861),\n",
              " ('업', 12978),\n",
              " ('하', 178051),\n",
              " ('였', 41292),\n",
              " ('그', 58693),\n",
              " ('후', 25082),\n",
              " ('해', 56091),\n",
              " ('군', 23518),\n",
              " ('들', 64815),\n",
              " ('가', 130773),\n",
              " ('전', 58792),\n",
              " ('함', 13220),\n",
              " ('·', 11833),\n",
              " ('원', 39547),\n",
              " ('자', 72497),\n",
              " ('력', 14231),\n",
              " ('잠', 1185),\n",
              " ('수', 65819),\n",
              " ('의', 245951),\n",
              " ('승', 8023),\n",
              " ('무', 20662),\n",
              " ('으', 96586),\n",
              " ('로', 168430),\n",
              " ('5', 33395),\n",
              " ('위', 36477),\n",
              " ('예', 11162),\n",
              " ('편', 8755),\n",
              " ('고', 129058),\n",
              " ('땅', 1169),\n",
              " ('콩', 808),\n",
              " ('면', 26992),\n",
              " ('화', 33843),\n",
              " ('등', 26727),\n",
              " ('꿔', 109),\n",
              " ('많', 9542),\n",
              " ('은', 118648),\n",
              " ('돈', 1028),\n",
              " ('벌', 3512),\n",
              " ('었', 51482),\n",
              " ('별', 5624),\n",
              " ('명', 28905)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BU8lnsP0DU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8b612f-7e2d-41cd-84e6-2ce5bce95944"
      },
      "source": [
        "# 각 글자별 고유한 번호 부여\n",
        "char_to_id = {'[PAD]': 0, '[UNK]': 1}\n",
        "char_to_id"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0, '[UNK]': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9yga4OMoj2OA",
        "outputId": "5cd71395-5946-4007-a6da-31ff6c204873"
      },
      "source": [
        "chr(120) # 숫자를 문자로(ascii)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'x'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErRIzBim0MmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c94d770-fccc-4c28-df82-9c7ece8534db"
      },
      "source": [
        "# Ascii 등록\n",
        "index_s, index_e = 32, 126 # ascii range\n",
        "for index in range(index_s, index_e + 1):\n",
        "    char_to_id[chr(index)] = len(char_to_id)\n",
        "len(char_to_id), list(char_to_id.items())[-20:]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97,\n",
              " [('k', 77),\n",
              "  ('l', 78),\n",
              "  ('m', 79),\n",
              "  ('n', 80),\n",
              "  ('o', 81),\n",
              "  ('p', 82),\n",
              "  ('q', 83),\n",
              "  ('r', 84),\n",
              "  ('s', 85),\n",
              "  ('t', 86),\n",
              "  ('u', 87),\n",
              "  ('v', 88),\n",
              "  ('w', 89),\n",
              "  ('x', 90),\n",
              "  ('y', 91),\n",
              "  ('z', 92),\n",
              "  ('{', 93),\n",
              "  ('|', 94),\n",
              "  ('}', 95),\n",
              "  ('~', 96)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jorZItLskK-z",
        "outputId": "387b04d2-64a6-49b7-c7f2-4ba5b54a3cf2"
      },
      "source": [
        "ord('가'), chr(44032)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44032, '가')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn_jYJoH0i2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956ef143-9c13-45c3-e895-a4d8c30c89e9"
      },
      "source": [
        "# 한글 등록\n",
        "index_s, index_e = ord('가'), ord('힣') # ord : unicode to int\n",
        "for index in range(index_s, index_e + 1):\n",
        "    char_to_id[chr(index)] = len(char_to_id)\n",
        "len(char_to_id), list(char_to_id.items())[-20:]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11269,\n",
              " [('힐', 11249),\n",
              "  ('힑', 11250),\n",
              "  ('힒', 11251),\n",
              "  ('힓', 11252),\n",
              "  ('힔', 11253),\n",
              "  ('힕', 11254),\n",
              "  ('힖', 11255),\n",
              "  ('힗', 11256),\n",
              "  ('힘', 11257),\n",
              "  ('힙', 11258),\n",
              "  ('힚', 11259),\n",
              "  ('힛', 11260),\n",
              "  ('힜', 11261),\n",
              "  ('힝', 11262),\n",
              "  ('힞', 11263),\n",
              "  ('힟', 11264),\n",
              "  ('힠', 11265),\n",
              "  ('힡', 11266),\n",
              "  ('힢', 11267),\n",
              "  ('힣', 11268)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNz3x3Wk0x82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc25eea-5cfa-48e1-b9fe-8a211ce8b941"
      },
      "source": [
        "# vocab 출력\n",
        "print(f\"전체: {len(char_to_id)}\")\n",
        "print(f\"10개: {list(char_to_id.items())[:10]}\")\n",
        "print(f\"alphabet: {list(char_to_id.items())[35:45]}\")\n",
        "print(f\"한글처음: {list(char_to_id.items())[97:107]}\")\n",
        "print(f\"한글마지막: {list(char_to_id.items())[-10:]}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체: 11269\n",
            "10개: [('[PAD]', 0), ('[UNK]', 1), (' ', 2), ('!', 3), ('\"', 4), ('#', 5), ('$', 6), ('%', 7), ('&', 8), (\"'\", 9)]\n",
            "alphabet: [('A', 35), ('B', 36), ('C', 37), ('D', 38), ('E', 39), ('F', 40), ('G', 41), ('H', 42), ('I', 43), ('J', 44)]\n",
            "한글처음: [('가', 97), ('각', 98), ('갂', 99), ('갃', 100), ('간', 101), ('갅', 102), ('갆', 103), ('갇', 104), ('갈', 105), ('갉', 106)]\n",
            "한글마지막: [('힚', 11259), ('힛', 11260), ('힜', 11261), ('힝', 11262), ('힞', 11263), ('힟', 11264), ('힠', 11265), ('힡', 11266), ('힢', 11267), ('힣', 11268)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gy23lLt1XEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833c3973-1826-415c-d519-3b414a806ee2"
      },
      "source": [
        "# tokenize\n",
        "char_tokens, char_ids = [], []\n",
        "for c in text:\n",
        "    if c == '\\n':\n",
        "        continue\n",
        "    else:\n",
        "        char_tokens.append(c)\n",
        "        char_ids.append(char_to_id.get(c, 1)) # vocab 에 없는 경우 1번을 준다(1은 unk-unknown)\n",
        "\n",
        "# 결과 출력 (최초 64개만 출력)\n",
        "print(char_tokens[:64])\n",
        "print(char_ids[:64])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['위', '키', '백', '과', '의', ' ', '최', '상', '위', ' ', '도', '메', '인', '이', ' ', '.', 'c', 'o', 'm', '이', '던', ' ', '시', '절', ' ', 'k', 'o', '.', 'w', 'i', 'k', 'i', 'p', 'e', 'd', 'i', 'a', '.', 'c', 'o', 'm', '에', ' ', '구', '판', ' ', '미', '디', '어', '위', '키', '가', ' ', '깔', '렸', '으', '나', ' ', '한', '글', ' ', '처', '리', '에']\n",
            "[7013, 9477, 4242, 349, 7097, 2, 8637, 5410, 7013, 2, 2085, 3765, 7129, 7125, 2, 16, 69, 81, 79, 7125, 1977, 2, 5949, 7273, 2, 77, 81, 16, 89, 75, 77, 75, 82, 71, 70, 75, 67, 16, 69, 81, 79, 6705, 2, 461, 10097, 2, 4185, 2421, 6677, 7013, 9477, 97, 2, 693, 3225, 7069, 1273, 2, 10685, 609, 2, 8441, 3597, 6705]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTeR0MZ72PCE"
      },
      "source": [
        "# Word Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqFc_FMYla5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1ba528-ca29-4caa-88e0-032faf717d4c"
      },
      "source": [
        "word_counter = collections.defaultdict(int)\n",
        "# word 개수 확인\n",
        "with zipfile.ZipFile(os.path.join(kowiki_dir, 'kowiki.txt.zip')) as z:\n",
        "    with z.open('kowiki.txt') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 100000:\n",
        "                break\n",
        "            line = line.decode('utf-8').strip()\n",
        "            for w in line.split():\n",
        "                word_counter[w] += 1\n",
        "len(word_counter)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "687561"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVHP-cqllo_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fcc973e-0528-40bf-ed3f-a86c20a3f755"
      },
      "source": [
        "list(word_counter.items())[:100]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('지미', 52),\n",
              " ('카터', 29),\n",
              " ('제임스', 253),\n",
              " ('얼', 4),\n",
              " ('\"지미\"', 1),\n",
              " ('주니어(,', 1),\n",
              " ('1924년', 124),\n",
              " ('10월', 1631),\n",
              " ('1일', 591),\n",
              " ('~', 1248),\n",
              " (')는', 623),\n",
              " ('민주당', 236),\n",
              " ('출신', 302),\n",
              " ('미국', 2285),\n",
              " ('39대', 1),\n",
              " ('대통령', 1189),\n",
              " ('(1977년', 1),\n",
              " ('1981년)이다.', 1),\n",
              " ('카터는', 15),\n",
              " ('조지아주', 12),\n",
              " ('섬터', 4),\n",
              " ('카운티', 20),\n",
              " ('플레인스', 1),\n",
              " ('마을에서', 35),\n",
              " ('태어났다.', 423),\n",
              " ('조지아', 34),\n",
              " ('공과대학교를', 2),\n",
              " ('졸업하였다.', 49),\n",
              " ('그', 11637),\n",
              " ('후', 2786),\n",
              " ('해군에', 15),\n",
              " ('들어가', 197),\n",
              " ('전함·원자력·잠수함의', 1),\n",
              " ('승무원으로', 1),\n",
              " ('일하였다.', 29),\n",
              " ('1953년', 145),\n",
              " ('해군', 156),\n",
              " ('대위로', 11),\n",
              " ('예편하였고', 1),\n",
              " ('이후', 5490),\n",
              " ('땅콩·면화', 1),\n",
              " ('등을', 2429),\n",
              " ('가꿔', 1),\n",
              " ('많은', 4731),\n",
              " ('돈을', 218),\n",
              " ('벌었다.', 11),\n",
              " ('그의', 5161),\n",
              " ('별명이', 30),\n",
              " ('\"땅콩', 1),\n",
              " ('농부\"', 1),\n",
              " ('(Peanut', 1),\n",
              " ('Farmer)로', 1),\n",
              " ('알려졌다.', 211),\n",
              " ('1962년', 196),\n",
              " ('주', 839),\n",
              " ('상원', 43),\n",
              " ('의원', 163),\n",
              " ('선거에서', 266),\n",
              " ('낙선하나', 1),\n",
              " ('선거가', 68),\n",
              " ('부정선거', 15),\n",
              " ('였음을', 1),\n",
              " ('입증하게', 2),\n",
              " ('되어', 1504),\n",
              " ('당선되고,', 3),\n",
              " ('1966년', 103),\n",
              " ('지사', 13),\n",
              " ('선거에', 114),\n",
              " ('낙선하지만', 1),\n",
              " ('1970년', 168),\n",
              " ('지사를', 16),\n",
              " ('역임했다.', 42),\n",
              " ('대통령이', 457),\n",
              " ('되기', 168),\n",
              " ('전', 1775),\n",
              " ('상원의원을', 3),\n",
              " ('두번', 15),\n",
              " ('연임했으며,', 1),\n",
              " ('1971년부터', 9),\n",
              " ('1975년까지', 6),\n",
              " ('지사로', 8),\n",
              " ('근무했다.', 14),\n",
              " ('주지사로', 42),\n",
              " ('지내면서,', 1),\n",
              " ('미국에', 207),\n",
              " ('사는', 332),\n",
              " ('흑인', 118),\n",
              " ('등용법을', 1),\n",
              " ('내세웠다.', 41),\n",
              " ('1976년', 118),\n",
              " ('미합중국', 22),\n",
              " ('(미국)', 2),\n",
              " ('제39대', 2),\n",
              " ('후보로', 147),\n",
              " ('출마하여', 29),\n",
              " ('도덕주의', 2),\n",
              " ('정책으로', 80),\n",
              " ('내세워서,', 1),\n",
              " ('지지를', 275),\n",
              " ('받고', 619)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilAQSXNr2SAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55482dd9-1f10-4b8e-d4e4-1479367437d8"
      },
      "source": [
        "# 각 단어별 고유한 번호 부여\n",
        "word_to_id = {'[PAD]': 0, '[UNK]': 1}\n",
        "word_to_id"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0, '[UNK]': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjwhTj-Q7IxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa67d41e-20de-4979-a3db-993cc8b759e9"
      },
      "source": [
        "# 단어 목록을 생성. set을 이용해 중복 제거\n",
        "words = list(dict.fromkeys(text.split()))\n",
        "print(f\"words: {words}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "words: ['위키백과의', '최상위', '도메인이', '.com이던', '시절', 'ko.wikipedia.com에', '구판', '미디어위키가', '깔렸으나', '한글', '처리에', '문제가', '있어', '글을', '올릴', '수도', '없는', '이름뿐인', '곳이었다.', '2002년', '10월에', '새로운', '위키', '소프트웨어를', '쓰면서', '처리', '풀리기', '시작했지만,', '가장', '많은', '사람이', '쓰는', '인터넷', '익스플로러에서는', '인코딩', '여전했다.', '이런', '이유로', '초기에는', '도움말을', '옮기거나', '일에', '어려움을', '겪었다.', '어려움이', '있었는데도', '위키백과', '통계로는,', '10월에서', '2003년', '7월까지', '열', '달', '사이에', '글이', '13개에서', '159개로', '늘었고', '7월과', '8월', '사이에는', '한', '만에', '159개에서', '348개로', '늘어났다.', '9월부터는', '익스플로러의', '사라졌으며,', '대한민국', '언론에서도', '몇', '차례', '위키백과를', '소개하면서', '참여자가', '점증하리라고', '예측했다.', '참고로', '한국어', '최초', '문서는', '10월', '12일에', '등재된', '지미', '카터', '문서이다.', '2005년', '6월', '5일', '양자장론', '문서', '등재를', '기점으로', '총', '등재', '수가', '1만', '개를', '돌파하였고', '이어', '동해', '11월에', '제1회', '정보트러스트', '어워드', '문화', '일반', '분야에', '선정되었다.', '2007년', '9일에는', '한겨레21에서', '위키백과와', '오프라인', '첫', '모임을', '취재한', '기사를', '표지', '이야기로', '다루었다.', '2008년', '광우병', '촛불', '시위', '때', '생긴', '신조어인', '명박산성이', '위키백과에', '등재되고', '이', '문서의', '존치', '여부를', '두고', '갑론을박의', '과정이', '화제가', '되고', '각종', '매체에도', '보도가', '되었다.', '시위대의', '난입과', '충돌을', '방지하기', '위해', '거리에', '설치되었던', '컨테이너', '박스를', '이명박', '정부의', '불통으로', '풍자를', '하기', '사용된', '신조어는', '중립성을', '지켰는지와', '백과사전에', '올라올', '만한', '문서인지가', '쟁점이', '되었는데', '일시적으로', '신조어일', '뿐이라는', '주장과', '이미', '여러', '매체에서', '사용되어', '지속성이', '보장되었다는', '주장', '등', '논쟁이', '벌어졌고', '다음', '아고라', '등지에서', '항목을', '존치하는', '방안을', '지지하는', '의견을', '남기기', '새로', '가입하는', '혼란이', '빚어졌다.', '11월', '4일에는', '다음커뮤니케이션에서', '글로벌', '세계', '대백과사전을', '기증받았으며,', '2009년', '3월에는', '서울특별시로부터', '콘텐츠를', '기증받았다.', '액세스권', '10만', '개', '수를', '돌파했다.', '2011년', '4월', '16일에는', '대한민국에서의', '위키미디어', '프로젝트를', '지원하는', '결성할', '것을', '추진하는', '논의가', '이뤄졌고', '이후', '창립준비위원회', '결성을', '거쳐', '2014년', '19일', '창립총회를', '개최하였으며,', '최종적으로', '2015년', '4일', '사단법인', '한국', '협회가', '결성되어', '활동', '중에', '있다.', '2019년', '미국', '위키미디어재단으로부터', '지역', '지부(챕터)로', '승인을', '받았다.', '2012년', '5월', '19일에는', '보비', '탬블링', '20만', '문서가', '등재되었고', '1월', '5일,', 'Rojo', '-Tierra-', '30만', '등재되었다.', '2017년', '21일에는', '충청남도', '동물위생시험소', '등재로', '40만', '개의', '문서까지']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBCpizPmOpAS"
      },
      "source": [
        "# 단어를 vocab에 등록\n",
        "for word in words:\n",
        "    word_to_id[word] = len(word_to_id)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_hGa2iW7U54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d96fe35-2cda-40e1-c9ce-b1bb3f9e6693"
      },
      "source": [
        "# vocab 개수 출력\n",
        "print(f\"전체: {len(word_to_id)}\")\n",
        "print(f\"처음 10개: {list(word_to_id.items())[:10]}\")\n",
        "print(f\"마지막 10개: {list(word_to_id.items())[-10:]}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체: 275\n",
            "처음 10개: [('[PAD]', 0), ('[UNK]', 1), ('위키백과의', 2), ('최상위', 3), ('도메인이', 4), ('.com이던', 5), ('시절', 6), ('ko.wikipedia.com에', 7), ('구판', 8), ('미디어위키가', 9)]\n",
            "마지막 10개: [('30만', 265), ('등재되었다.', 266), ('2017년', 267), ('21일에는', 268), ('충청남도', 269), ('동물위생시험소', 270), ('등재로', 271), ('40만', 272), ('개의', 273), ('문서까지', 274)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWFobYYB7bOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d5d7f9-416f-4e78-ab03-65b706287705"
      },
      "source": [
        "# tokenize\n",
        "word_tokens, word_ids = [], []\n",
        "for word in text.split():\n",
        "    word_tokens.append(word)\n",
        "    word_ids.append(word_to_id.get(word, 1))\n",
        "\n",
        "# 결과 출력 (최초 64개만 출력)\n",
        "print(word_tokens[:64])\n",
        "print(word_ids[:64])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['위키백과의', '최상위', '도메인이', '.com이던', '시절', 'ko.wikipedia.com에', '구판', '미디어위키가', '깔렸으나', '한글', '처리에', '문제가', '있어', '글을', '올릴', '수도', '없는', '이름뿐인', '곳이었다.', '2002년', '10월에', '새로운', '위키', '소프트웨어를', '쓰면서', '한글', '처리', '문제가', '풀리기', '시작했지만,', '가장', '많은', '사람이', '쓰는', '인터넷', '익스플로러에서는', '인코딩', '문제가', '여전했다.', '이런', '이유로', '초기에는', '도움말을', '옮기거나', '쓰는', '일에', '어려움을', '겪었다.', '이런', '어려움이', '있었는데도', '위키백과', '통계로는,', '2002년', '10월에서', '2003년', '7월까지', '열', '달', '사이에', '글이', '13개에서', '159개로', '늘었고']\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 11, 27, 13, 28, 29, 30, 31, 32, 33, 34, 35, 36, 13, 37, 38, 39, 40, 41, 42, 33, 43, 44, 45, 38, 46, 47, 48, 49, 21, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3yuLfj87wIi"
      },
      "source": [
        "# BPE (Byte Pair Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD5IhK5U8ABz"
      },
      "source": [
        "# 최초 말뭉치 빈도수\n",
        "bpe_counter = {'_ l o w': 5,\n",
        "         '_ l o w e r': 2,\n",
        "         '_ n e w e s t': 6,\n",
        "         '_ w i d e s t': 3\n",
        "         }"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNHg5nXdmi7N",
        "outputId": "fdad0547-e14d-4065-c9f4-2fca86d291b5"
      },
      "source": [
        "# 각 subword에 고유한 번호 부여\n",
        "bpe_to_id = {'[PAD]': 0, '[UNK]': 1}\n",
        "bpe_to_id"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0, '[UNK]': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ilMJB5hqFNR"
      },
      "source": [
        "def get_vocab(counter, vocab):\n",
        "    for word, freq in counter.items():\n",
        "        tokens = word.split()\n",
        "        for token in tokens:\n",
        "            if token not in vocab:\n",
        "                vocab[token] = len(bpe_to_id)\n",
        "    return vocab"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsE4WYxuqkiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1308b3-e988-40a5-be46-6f9c7b6c9cb1"
      },
      "source": [
        "bpe_to_id = get_vocab(bpe_counter, bpe_to_id)\n",
        "len(bpe_to_id), bpe_to_id"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,\n",
              " {'[PAD]': 0,\n",
              "  '[UNK]': 1,\n",
              "  '_': 2,\n",
              "  'd': 12,\n",
              "  'e': 6,\n",
              "  'i': 11,\n",
              "  'l': 3,\n",
              "  'n': 8,\n",
              "  'o': 4,\n",
              "  'r': 7,\n",
              "  's': 9,\n",
              "  't': 10,\n",
              "  'w': 5})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsGCikDE7yPy"
      },
      "source": [
        "def get_bi_gram(counter):\n",
        "    \"\"\"\n",
        "    bi-gram 횟수를 구하는 함수\n",
        "    :param counter: bpe counter\n",
        "    :return: bi-gram 빈도수 dictionary\n",
        "    \"\"\"\n",
        "    pairs = collections.defaultdict(int)  # 새로운 단어는 기본 값 0\n",
        "    for word, freq in counter.items():\n",
        "        tokens = word.split() # 값은 띄어쓰기로 구분 되어 있음 'l o v e'\n",
        "        print('token : ', tokens)\n",
        "        for i in range(len(tokens) - 1): # 2개씩 자를거니까 len - 1\n",
        "            print('freq : ', freq)\n",
        "            pairs[(tokens[i], tokens[i + 1])] += freq # 이전 단어와 다음 단어의 빈도수\n",
        "    return pairs"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew4H1AXpPizB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da54d119-be4b-4ae1-df9e-b83e1ae0b4dc"
      },
      "source": [
        "pairs = get_bi_gram(bpe_counter)\n",
        "pairs"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "token :  ['_', 'l', 'o', 'w']\n",
            "freq :  5\n",
            "freq :  5\n",
            "freq :  5\n",
            "token :  ['_', 'l', 'o', 'w', 'e', 'r']\n",
            "freq :  2\n",
            "freq :  2\n",
            "freq :  2\n",
            "freq :  2\n",
            "freq :  2\n",
            "token :  ['_', 'n', 'e', 'w', 'e', 's', 't']\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "token :  ['_', 'w', 'i', 'd', 'e', 's', 't']\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('_', 'l'): 7,\n",
              "             ('_', 'n'): 6,\n",
              "             ('_', 'w'): 3,\n",
              "             ('d', 'e'): 3,\n",
              "             ('e', 'r'): 2,\n",
              "             ('e', 's'): 9,\n",
              "             ('e', 'w'): 6,\n",
              "             ('i', 'd'): 3,\n",
              "             ('l', 'o'): 7,\n",
              "             ('n', 'e'): 6,\n",
              "             ('o', 'w'): 7,\n",
              "             ('s', 't'): 9,\n",
              "             ('w', 'e'): 8,\n",
              "             ('w', 'i'): 3})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KySjXHTrYuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df53ba5f-728e-41b2-d44c-cc1abd6c0c5f"
      },
      "source": [
        "best = max(pairs, key=pairs.get)  # value 이 가장 큰 pair 조회\n",
        "best"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('e', 's')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6QEXfNdKqwoG",
        "outputId": "b5bcaf46-848a-4570-c52b-ffeb31a6ff01"
      },
      "source": [
        "' '.join(best)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'e s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JSVFnCEUq9ou",
        "outputId": "a3fc1345-f088-4c6f-e5c6-3c3d595b2f9b"
      },
      "source": [
        "re.escape(' '.join(best)) # 영문자, 숫자가 아닌 문자에 대하여 백슬러시 문자를 추가한다"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'e\\\\ s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLNluCa478xq"
      },
      "source": [
        "def merge_counter(pair, counter_in):\n",
        "    \"\"\"\n",
        "    bi-gram을 합치는 함수\n",
        "    :param pair: bi-gram pair\n",
        "    :param counter_in: 현재 bpe counter\n",
        "    :return: bi-gram이 합쳐진 새로운 counter\n",
        "    \"\"\"\n",
        "    counter_out = {}\n",
        "    # 두 단어를 의미하는 regex 생성\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    # not a whitespace character: \\S\n",
        "    # negative lookbehind assertion: (?<!...)\n",
        "    # negative lookahead assertion: (?!...)\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)') # 앞 뒤가 글자가 아니어야 한다 (문자 e s 문자)\n",
        "    print('p : ', p)\n",
        "    unigram = ''.join(pair) # best를 붙여서 하나의 vocab으로\n",
        "    print(f'bigram: {bigram} -> unigram: {unigram}')\n",
        "    for word in counter_in:\n",
        "        print('word : ', word)\n",
        "        w_out = p.sub(unigram, word)  # bigram(띄어쓰기 e s)을 unigram(붙여쓰기 es)으로 변경\n",
        "        print('w_out : ', w_out)\n",
        "        counter_out[w_out] = counter_in[word]\n",
        "    return counter_out"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1752KnYPvc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684f6cf6-5557-4c9f-e1b8-b395c8aa0b1d"
      },
      "source": [
        "merge_counter(best, bpe_counter) # best는 하나의 vocab으로 볼 수 있도록 붙였다"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p :  re.compile('(?<!\\\\S)e\\\\ s(?!\\\\S)')\n",
            "bigram: e\\ s -> unigram: es\n",
            "word :  _ l o w\n",
            "w_out :  _ l o w\n",
            "word :  _ l o w e r\n",
            "w_out :  _ l o w e r\n",
            "word :  _ n e w e s t\n",
            "w_out :  _ n e w es t\n",
            "word :  _ w i d e s t\n",
            "w_out :  _ w i d es t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_ l o w': 5, '_ l o w e r': 2, '_ n e w es t': 6, '_ w i d es t': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etG5a0468Dm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f503be-742e-44be-de16-57627cfe75be"
      },
      "source": [
        "# 돌릴수록 best 끼리 붙은 vocab이 만들어진다\n",
        "for i in range(1):\n",
        "    pairs = get_bi_gram(bpe_counter)\n",
        "    print(\"pairs:\", pairs)\n",
        "    best = max(pairs, key=pairs.get)  # value 이 가장 큰 pair 조회\n",
        "    print(\"best:\", best)\n",
        "    bpe_counter = merge_counter(best, bpe_counter) # best는 하나의 vocab 으로 변경\n",
        "    print(\"counter:\", bpe_counter)\n",
        "    bpe_to_id = get_vocab(bpe_counter, bpe_to_id) # 단어가 l o w es t 로 되었으니 다시 split해서(l, o, w, es, t) vocab에 새로운 것을(es) 추가한다\n",
        "    print(\"vocab:\", bpe_to_id)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "token :  ['_', 'l', 'o', 'w']\n",
            "freq :  5\n",
            "freq :  5\n",
            "freq :  5\n",
            "token :  ['_', 'l', 'o', 'w', 'e', 'r']\n",
            "freq :  2\n",
            "freq :  2\n",
            "freq :  2\n",
            "freq :  2\n",
            "freq :  2\n",
            "token :  ['_', 'n', 'e', 'w', 'e', 's', 't']\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "freq :  6\n",
            "token :  ['_', 'w', 'i', 'd', 'e', 's', 't']\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n",
            "freq :  3\n",
            "pairs: defaultdict(<class 'int'>, {('_', 'l'): 7, ('l', 'o'): 7, ('o', 'w'): 7, ('w', 'e'): 8, ('e', 'r'): 2, ('_', 'n'): 6, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('_', 'w'): 3, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3})\n",
            "best: ('e', 's')\n",
            "p :  re.compile('(?<!\\\\S)e\\\\ s(?!\\\\S)')\n",
            "bigram: e\\ s -> unigram: es\n",
            "word :  _ l o w\n",
            "w_out :  _ l o w\n",
            "word :  _ l o w e r\n",
            "w_out :  _ l o w e r\n",
            "word :  _ n e w e s t\n",
            "w_out :  _ n e w es t\n",
            "word :  _ w i d e s t\n",
            "w_out :  _ w i d es t\n",
            "counter: {'_ l o w': 5, '_ l o w e r': 2, '_ n e w es t': 6, '_ w i d es t': 3}\n",
            "vocab: {'[PAD]': 0, '[UNK]': 1, '_': 2, 'l': 3, 'o': 4, 'w': 5, 'e': 6, 'r': 7, 'n': 8, 's': 9, 't': 10, 'i': 11, 'd': 12, 'es': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7GZHAJc8R1W"
      },
      "source": [
        "# Google sentencepiece를 이용해 vocab 생성\n",
        "- https://github.com/google/sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ajMz_ZCCxs"
      },
      "source": [
        "## sentencepe 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQKAKbPN6miL"
      },
      "source": [
        "os.listdir(kowiki_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d99Y3Fkdvftw"
      },
      "source": [
        "shutil.copy(os.path.join(kowiki_dir, 'kowiki.txt.zip'), './')\n",
        "os.listdir('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KE9ITMQvq5X"
      },
      "source": [
        "!unzip kowiki.txt.zip\n",
        "os.listdir('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwDPlGeeCF70"
      },
      "source": [
        "def train_sentencepiece(corpus, prefix, vocab_size=32000):\n",
        "    \"\"\"\n",
        "    sentencepiece를 이용해 vocab 학습\n",
        "    :param corpus: 학습할 말뭉치\n",
        "    :param prefix: 저장할 vocab 이름\n",
        "    :param vocab_size: vocab 개수\n",
        "    \"\"\"\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +  # 7은 특수문자 개수\n",
        "        \" --model_type=unigram\" +\n",
        "        \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
        "        \" --pad_id=0 --pad_piece=[PAD]\" +  # pad token 및 id 지정\n",
        "        \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown token 및 id 지정\n",
        "        \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence token 및 id 지정(문장의 시작)\n",
        "        \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence token 및 id 지정(문장의 끝)\n",
        "        \" --user_defined_symbols=[SEP],[CLS],[MASK]\")  # 기타 추가 토큰 SEP: 4, CLS: 5, MASK: 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE-yJ_cSCYz0"
      },
      "source": [
        "# vocab 생성(시간이 오래걸림)\n",
        "train_sentencepiece(f\"kowiki.txt\", f\"ko_32000\", vocab_size=32000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85eoYIgZNtYa"
      },
      "source": [
        "os.listdir(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkEboWWyNhlT"
      },
      "source": [
        "# 생성된 vocab 복사\n",
        "shutil.copy(\"ko_32000.model\", f\"{data_dir}/ko_32000.model\")\n",
        "shutil.copy(\"ko_32000.vocab\", f\"{data_dir}/ko_32000.vocab\")\n",
        "os.listdir(f\"{data_dir}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeBCtb61bG8Y"
      },
      "source": [
        "## sentencepe 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjtyzUGbLwg"
      },
      "source": [
        "# load vocab\n",
        "spm_vocab = spm.SentencePieceProcessor()\n",
        "spm_vocab.load(f\"{data_dir}/ko_32000.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJrlfRqObeEI"
      },
      "source": [
        "# vocab 출력\n",
        "print(f\"len: {len(spm_vocab)}\")\n",
        "for id in range(16):\n",
        "    print(f\"{id:2d}: {spm_vocab.id_to_piece(id)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWlGnwd9bh67"
      },
      "source": [
        "# text를 tokenize 함\n",
        "# sentence to pieces\n",
        "###############################\n",
        "pieces = spm_vocab.encode_as_pieces(text)\n",
        "print(pieces)\n",
        "###############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aaBGd8R_Ue3"
      },
      "source": [
        "###############################\n",
        "spm_vocab.encode_as_pieces('나는 오늘 서울에 놀러 갔다')\n",
        "###############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lUjSWh_MRX"
      },
      "source": [
        "###############################\n",
        "spm_vocab.encode_as_pieces('나는오늘서울에놀러갔다')\n",
        "###############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2PsfHS7bt6j"
      },
      "source": [
        "# tokenize된 값을 string 으로 복원\n",
        "# pieces to sentence\n",
        "###############################\n",
        "spm_vocab.decode_pieces(pices)\n",
        "###############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NoPR4Tb5GB"
      },
      "source": [
        "# tokenize된 값을 id로 변경\n",
        "# piece to id\n",
        "piece_ids = []\n",
        "for piece in pieces:\n",
        "    ########################\n",
        "    _id = spm_vocab.piece_to_id(pieces)\n",
        "    piece_ids.append(_id)\n",
        "    ########################\n",
        "print(piece_ids[0:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6PGUrK9cHxZ"
      },
      "source": [
        "# text를 id로 tokenize 함\n",
        "# sentence to ids\n",
        "###############################\n",
        "ids = spm_vocab.encode_as_ids(text) # 바로 id로 바꿀 수 있다(위와 동일)\n",
        "print(ids)\n",
        "###############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyUkoxCpcUBj"
      },
      "source": [
        "# tokenize된 id 값을 string 으로 복원\n",
        "# id to sentence\n",
        "###############################\n",
        "spm_vocab.decode_ids(ids)\n",
        "###############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaPhB9Cjcbmi"
      },
      "source": [
        "# id 값을 token으로 변경\n",
        "# id to piece\n",
        "id_pieces = []\n",
        "for id in ids:\n",
        "    ########################\n",
        "    piece = spm_vocab.id_to_piece(id)\n",
        "    id_pieces.append(piece)\n",
        "    ########################\n",
        "print(id_pieces[0:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hEkA_iG1EWw"
      },
      "source": [
        "# 형태소 분석기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJLxb2Fc1JaY"
      },
      "source": [
        "# 행태소분석기 설치\n",
        "!set -x \\\n",
        "&& pip install konlpy \\\n",
        "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTuov7BO3VcV"
      },
      "source": [
        "import konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SagQRU1K3lRr"
      },
      "source": [
        "okt = konlpy.tag.Okt()\n",
        "okt.morphs(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXuDiUUs363E"
      },
      "source": [
        "mecab = konlpy.tag.Mecab()\n",
        "mecab.morphs(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgwPviyM4EUl"
      },
      "source": [
        "hannanum = konlpy.tag.Hannanum()\n",
        "hannanum.morphs(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pW4RVHU4K0N"
      },
      "source": [
        "komoran = konlpy.tag.Komoran()\n",
        "komoran.morphs(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51vG1bnj4REe"
      },
      "source": [
        "kkma = konlpy.tag.Kkma()\n",
        "kkma.morphs(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBf5UdAJ4iEP"
      },
      "source": [
        "mecab_counter = collections.defaultdict(int)\n",
        "# mecab tokenizer 개수 확인 (시간 오래 걸림)\n",
        "with zipfile.ZipFile(os.path.join(kowiki_dir, 'kowiki.txt.zip')) as z:\n",
        "    with z.open('kowiki.txt') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 100000:\n",
        "                break\n",
        "            line = line.decode('utf-8').strip()\n",
        "            for w in mecab.morphs(line):\n",
        "                mecab_counter[w] += 1\n",
        "len(mecab_counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16RFEQ_i4si5"
      },
      "source": [
        "list(mecab_counter.items())[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRPV8yHjgGMT"
      },
      "source": [
        "# 한국어 위키 다운로드 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ka6gXPBftct"
      },
      "source": [
        "# 한국어 위키 최신 dump 버전 다운로드\n",
        "!wget https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-meta-current.xml.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBMEC5AGgH28"
      },
      "source": [
        "# WikiExtractor 다운로드\n",
        "!wget https://github.com/paul-hyun/web-crawler/raw/master/WikiExtractor.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyPT41ishW-K"
      },
      "source": [
        "# 현재 폴더 파일 목록 확인\n",
        "os.listdir('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMQDxZU_hmdL"
      },
      "source": [
        "# WikiExtractor 실행 (30분 이상 오랜 시간 소요 됨)\n",
        "# -o: 출력할 폴더\n",
        "# --json: json format으로 출력\n",
        "os.system(f\"python WikiExtractor.py -o kowiki --json kowiki-latest-pages-meta-current.xml.bz2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpyY2oKIqxmy"
      },
      "source": [
        "with open(os.path.join('kowiki', 'AA', 'wiki_00')) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 10:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CugZgnZXq0hg"
      },
      "source": [
        "def list_wiki(dirname):\n",
        "    \"\"\"\n",
        "    위키 목록을 읽어들임\n",
        "    :param dirname: 위키 dir\n",
        "    :return: 위키 파일 목록\n",
        "    \"\"\"\n",
        "    filepaths = []\n",
        "    filenames = os.listdir(dirname)\n",
        "    for filename in filenames:\n",
        "        filepath = os.path.join(dirname, filename)\n",
        "\n",
        "        if os.path.isdir(filepath):\n",
        "            filepaths.extend(list_wiki(filepath))\n",
        "        else:\n",
        "            find = re.findall(r\"wiki_[0-9][0-9]\", filepath)\n",
        "            if 0 < len(find):\n",
        "                filepaths.append(filepath)\n",
        "    return sorted(filepaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzv-L0Wk0U3C"
      },
      "source": [
        "filepaths = []\n",
        "dirnames = os.listdir('kowiki')\n",
        "for dirname in dirnames:\n",
        "    dirpath = os.path.join('kowiki', dirname)\n",
        "    filenames = os.listdir(dirpath)\n",
        "    for filename in filenames:\n",
        "        if filename.startswith('wiki_'):\n",
        "            filepath = os.path.join(dirpath, filename)\n",
        "            filepaths.append(filepath)\n",
        "filepaths = sorted(filepaths)\n",
        "print(len(filepaths), filepaths[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9e5nxqV0lYo"
      },
      "source": [
        "def trim_text(item):\n",
        "    \"\"\"\n",
        "    한 위키 문서 내의 여러줄띄기(\\n\\n...)를 한줄띄기로(\\n)로 변경\n",
        "    :param item: 위키 항목\n",
        "    :return: text의 여러줄 new line을 한 줄 new line으로 변경한 json data\n",
        "    \"\"\"\n",
        "    data = json.loads(item)\n",
        "    text = data[\"text\"]\n",
        "    value = list(filter(lambda x: len(x) > 0, text.split('\\n')))\n",
        "    data[\"text\"] = \"\\n\".join(value)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Bwzibq2_k7"
      },
      "source": [
        "# 여러줄띄기(\\n\\n...)를 한줄띄기로(\\n)로 변경\n",
        "dataset = []\n",
        "for filepath in tqdm(filepaths):\n",
        "    with open(filepath, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                dataset.append(trim_text(line))\n",
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhEzFlnl3zXt"
      },
      "source": [
        "# 위키를 한 파일로 저장\n",
        "with open(\"kowiki.txt\", \"w\") as f:\n",
        "    for data in tqdm(dataset):\n",
        "        f.write(data[\"text\"])\n",
        "        f.write(\"\\n\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH0_9g0a57wq"
      },
      "source": [
        "# 파일 내용 확인\n",
        "with open(\"kowiki.txt\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 30:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNS5lo4G5X78"
      },
      "source": [
        "# 압축\n",
        "!zip kowiki.txt.zip kowiki.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRxXAST6563O"
      },
      "source": [
        "# 압축파일 보관\n",
        "shutil.move('kowiki.txt.zip', os.path.join(kowiki_dir, 'kowiki.txt.zip'))\n",
        "os.listdir(kowiki_dir)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}