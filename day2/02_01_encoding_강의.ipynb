{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-01-encoding-강의.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujin2021/NLP_CAMP/blob/main/day2/02_01_encoding_%EA%B0%95%EC%9D%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHkHg6XAXoyK"
      },
      "source": [
        "# Evn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYXFwcBXJDG"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import json\n",
        "import zipfile\n",
        "import math\n",
        "import copy\n",
        "import collections\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvjyruUlXtlR"
      },
      "source": [
        "# random seed initialize - random값이 균일하게 나온다\n",
        "random_seed = 1234\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlEeZqo5MmS4"
      },
      "source": [
        "# One-hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H0BLydCb7lg"
      },
      "source": [
        "# one hot encoding text\n",
        "text = \"\"\"나는 책을 샀다\n",
        "나는 책을 본다\n",
        "나는 책을 팔았다\n",
        "나는 책을 서점에서 샀다\n",
        "나는 책을 도서관에서 본다\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYkW9ulfMsJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dcd813c-fdaf-4238-e114-50bc0e8fff3d"
      },
      "source": [
        "# 띄어쓰기 단위로 split\n",
        "tokens = text.split()\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['나는',\n",
              " '책을',\n",
              " '샀다',\n",
              " '나는',\n",
              " '책을',\n",
              " '본다',\n",
              " '나는',\n",
              " '책을',\n",
              " '팔았다',\n",
              " '나는',\n",
              " '책을',\n",
              " '서점에서',\n",
              " '샀다',\n",
              " '나는',\n",
              " '책을',\n",
              " '도서관에서',\n",
              " '본다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBy3trarM9K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98644e1-9e43-42be-fdae-806e3b9ae512"
      },
      "source": [
        "# vocab 중복제거\n",
        "words = list(dict.fromkeys(tokens))\n",
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['나는', '책을', '샀다', '본다', '팔았다', '서점에서', '도서관에서']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSndx7RxNDyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c4b0b6-9ac3-4763-9ec1-2ab4e112831f"
      },
      "source": [
        "# 각 단어에 고유한 번호 부여한 dictionary 생성\n",
        "word_to_id = {'[PAD]': 0, '[UNK]': 1}  # [PAD]: 길이 맞추는 용도, [UNK]: 알 수 없는 token\n",
        "for word in words:\n",
        "    word_to_id[word] = len(word_to_id)\n",
        "word_to_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0,\n",
              " '[UNK]': 1,\n",
              " '나는': 2,\n",
              " '도서관에서': 8,\n",
              " '본다': 5,\n",
              " '샀다': 4,\n",
              " '서점에서': 7,\n",
              " '책을': 3,\n",
              " '팔았다': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyxX8P0UNogt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4308a637-f182-46fb-b44b-c5ebe9bfd335"
      },
      "source": [
        "# 고유한 번호로 부터 단어를 찾을 수 있는 dictionary 생성\n",
        "id_to_word = {word:_id for _id, word in word_to_id.items()}\n",
        "id_to_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '[PAD]',\n",
              " 1: '[UNK]',\n",
              " 2: '나는',\n",
              " 3: '책을',\n",
              " 4: '샀다',\n",
              " 5: '본다',\n",
              " 6: '팔았다',\n",
              " 7: '서점에서',\n",
              " 8: '도서관에서'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH8CnhmuN4Ev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc50d8d2-26cb-48b0-e124-7119d042020e"
      },
      "source": [
        "# 줄바꿈 단위로 문장 분리\n",
        "sentences = text.split(\"\\n\")\n",
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['나는 책을 샀다', '나는 책을 본다', '나는 책을 팔았다', '나는 책을 서점에서 샀다', '나는 책을 도서관에서 본다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q330mF5IN6Q-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8e3db7-4764-4744-eb15-93ae8fc242fd"
      },
      "source": [
        "# 띄어쓰기 단위로 단어 분리\n",
        "tokens = []\n",
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "    tokens.append(sentence.split())\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "나는 책을 샀다\n",
            "나는 책을 본다\n",
            "나는 책을 팔았다\n",
            "나는 책을 서점에서 샀다\n",
            "나는 책을 도서관에서 본다\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['나는', '책을', '샀다'],\n",
              " ['나는', '책을', '본다'],\n",
              " ['나는', '책을', '팔았다'],\n",
              " ['나는', '책을', '서점에서', '샀다'],\n",
              " ['나는', '책을', '도서관에서', '본다']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mJPXOBJOOuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923b6d61-8938-4a27-f456-65017c909f00"
      },
      "source": [
        "# tokens을 vocabulary의 고유 번호로 변경\n",
        "token_ids = []\n",
        "for line_token in tokens:\n",
        "    token_ids.append([word_to_id[token] for token in line_token])\n",
        "token_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4], [2, 3, 5], [2, 3, 6], [2, 3, 7, 4], [2, 3, 8, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpL1RtY7OS1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7de7923-d3f6-4218-f85f-00210f6a0b40"
      },
      "source": [
        "# one hot encoding\n",
        "one_hot_encodings = [] # 모든 문장의 ont hot vector\n",
        "for line_token in token_ids: # 문장 -> 단어 -> 단어별 id\n",
        "    print(line_token)\n",
        "    one_hot_line = []  # 한 줄을 표현하는 벡터\n",
        "    for id in line_token: # 각 단어의 id\n",
        "        one_hot = [0] * len(word_to_id) # vector길이 만큼의 onehot을 만들어 준다\n",
        "        one_hot[id] = 1 # 각 단어에 해당하는 부분을 1로 변경\n",
        "        print(id, one_hot)\n",
        "        one_hot_line.append(one_hot)\n",
        "        \n",
        "    one_hot_encodings.append((one_hot_line))  # 라인을 전체 문서에 추가"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 3, 4]\n",
            "2 [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "3 [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "4 [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[2, 3, 5]\n",
            "2 [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "3 [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "5 [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[2, 3, 6]\n",
            "2 [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "3 [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "6 [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[2, 3, 7, 4]\n",
            "2 [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "3 [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "7 [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "4 [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[2, 3, 8, 5]\n",
            "2 [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "3 [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "8 [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "5 [0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USRtIkT4-PUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300c8763-8d9f-4d73-e2bc-ce5d6cca5431"
      },
      "source": [
        "one_hot_encodings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 0, 1, 0, 0, 0, 0]],\n",
              " [[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
              " [[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 0, 0, 0, 1, 0, 0]],\n",
              " [[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "  [0, 0, 0, 0, 1, 0, 0, 0, 0]],\n",
              " [[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "  [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "  [0, 0, 0, 0, 0, 1, 0, 0, 0]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ7Ce8spUskT",
        "outputId": "33cebd6c-88e1-4abc-ca6e-f591e6a0d74c"
      },
      "source": [
        "np.argmax(np.array(one_hot_encodings[0]), axis=-1) # numpy를 array로(?) 현재 길이가 안맞아서 하나만 해본다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_29J14jOtYq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "59c5c57f-c434-40df-fd5c-f7d73bb66d7f"
      },
      "source": [
        "# tensorflow one hot\n",
        "# token_ids가 앞 3개는 길이가 3 이지만 이후는 4로 tensorflow에서는 오류 발생 함(Can't convert non-rectangular Python sequence to Tensor.)\n",
        "# depth는 vocabulary 크기\n",
        "tf.one_hot(indices=token_ids, depth=len(word_to_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-424d4f9c4ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# depth는 vocabulary 크기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   4242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4243\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[0;32m-> 4244\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m   4245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[1;32m   6239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6240\u001b[0m       return one_hot_eager_fallback(\n\u001b[0;32m-> 6241\u001b[0;31m           indices, depth, on_value, off_value, axis=axis, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   6242\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6243\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot_eager_fallback\u001b[0;34m(indices, depth, on_value, off_value, axis, name, ctx)\u001b[0m\n\u001b[1;32m   6268\u001b[0m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_inputs_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mon_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moff_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6269\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mon_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moff_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inputs_T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6270\u001b[0;31m   \u001b[0m_attr_TI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6271\u001b[0m   \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6272\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moff_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMh8KXVbZ55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b390b28-f7fc-4581-b101-37f2c199f874"
      },
      "source": [
        "# token_ids가 앞 3개개만 one_hot으로 변경(앞의 3개는 길이가 같으므로 오류가 발생하지 않는다)\n",
        "tf.one_hot(indices=token_ids[:3], depth=len(word_to_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 9), dtype=float32, numpy=\n",
              "array([[[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWmcI_-YaMmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64007937-1d23-48d5-ac53-58b71e657630"
      },
      "source": [
        "# 모두 길이가 4가 되도록 pad(0) 추가\n",
        "pad_ids = []\n",
        "for line in token_ids:\n",
        "    line = line[:4]\n",
        "    line += [0] * (4 - len(line))\n",
        "    pad_ids.append(line)\n",
        "pad_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4, 0], [2, 3, 5, 0], [2, 3, 6, 0], [2, 3, 7, 4], [2, 3, 8, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVNudJ4-aT7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2897470f-6839-4197-be52-4f717ba3a72a"
      },
      "source": [
        "tf_one_hot_encodings = tf.one_hot(indices=pad_ids, depth=len(word_to_id))\n",
        "tf_one_hot_encodings # 3개짜리에 pad가 들어간 one hot을 넣어준다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4, 9), dtype=float32, numpy=\n",
              "array([[[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXCMJU7APHuz"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6VeeYocPF08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd32994-4ecf-4be3-c2ef-e11357c9ff25"
      },
      "source": [
        "# 랜덤 매트릭스 생성 (10 ~ 99), size : 8 x 4, id별\n",
        "weights = np.random.randint(10, 100, size=(len(word_to_id), 4)) / 100 \n",
        "weights # float"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.57, 0.93, 0.48, 0.63],\n",
              "       [0.86, 0.34, 0.25, 0.59],\n",
              "       [0.33, 0.36, 0.4 , 0.53],\n",
              "       [0.4 , 0.36, 0.68, 0.79],\n",
              "       [0.9 , 0.83, 0.57, 0.6 ],\n",
              "       [0.86, 0.47, 0.44, 0.48],\n",
              "       [0.77, 0.21, 0.1 , 0.85],\n",
              "       [0.9 , 0.13, 0.12, 0.29],\n",
              "       [0.22, 0.75, 0.85, 0.91]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYAhl1d2PdiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee6e6d9-3913-4811-fcd9-120b22e45dd1"
      },
      "source": [
        "# 첫번째 문장 만 numpy array로 변경\n",
        "one_hot_encoding_0 = np.array(one_hot_encodings[0])\n",
        "one_hot_encoding_0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFSdqtaZPuow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a35cf1-001c-4718-92b0-7c70e0add975"
      },
      "source": [
        "print(token_ids[0]) # [2, 3, 4]\n",
        "print(weights[token_ids[0][0]]) # weight[2] (id 2인 단어의 random matrix : [0.33 0.36 0.4  0.53])\n",
        "print(weights[token_ids[0][1]]) # weight[3]\n",
        "print(weights[token_ids[0][2]]) # weight[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 3, 4]\n",
            "[0.33 0.36 0.4  0.53]\n",
            "[0.4  0.36 0.68 0.79]\n",
            "[0.9  0.83 0.57 0.6 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1cG1z10Piv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c98d098-fe73-4766-af78-a0f6b8aa4a96"
      },
      "source": [
        "# one hot encoding은 matrix의 특정 row를 선택하는 것과 같은 결과, matmul : 행렬곱\n",
        "np.matmul(one_hot_encoding_0, weights) # one hot을 써야 한다(하지만 특별한 경우가아니면 one hot을 쓰지 않음 -> embedding, gather 을 사용)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33, 0.36, 0.4 , 0.53],\n",
              "       [0.4 , 0.36, 0.68, 0.79],\n",
              "       [0.9 , 0.83, 0.57, 0.6 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbf_h5TP_Ra"
      },
      "source": [
        "# tensorflow 에서도 tf.keras.layers.Embedding에서도 가능 함\n",
        "# weights 초기화를 위해서 [matrix] 형태로 변환함\n",
        "# embdding을 사용하면 token 번호를 바로 사용가능 함 현재 표준화된 방법\n",
        "embedding = tf.keras.layers.Embedding(len(word_to_id), 4, weights=[weights])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdPq5DDUQQwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b730ab0-55c9-48fa-86d1-5af6f614097b"
      },
      "source": [
        "embedding(np.array(token_ids[0])) # one hot vector를 만들지 않고 token id를 바로 쓸 수 있다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[0.33, 0.36, 0.4 , 0.53],\n",
              "       [0.4 , 0.36, 0.68, 0.79],\n",
              "       [0.9 , 0.83, 0.57, 0.6 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0DjjJuDQW1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca596b5-3b96-41c7-da81-14c1a6ded579"
      },
      "source": [
        "tf.gather(weights, np.array(token_ids[0])) # embedding과 gather이 같은 역할을 한다. one  hot을 쓰지 않고 바로 구할 수 있다(보통 one hot을 만들지 않고 이렇게 사용한다)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float64, numpy=\n",
              "array([[0.33, 0.36, 0.4 , 0.53],\n",
              "       [0.4 , 0.36, 0.68, 0.79],\n",
              "       [0.9 , 0.83, 0.57, 0.6 ]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVjo8R-Ia9vi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}